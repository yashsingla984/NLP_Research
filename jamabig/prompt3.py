import cloudscraper 
import requests
from bs4 import BeautifulSoup
import pandas as pd
from requests import get
import numpy as np
import time
import random
import re

import openai 

max_retries = 3
  
openai.api_key = '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'

# # messages = [ {"role": "system", "content":  
# #               "You are a intelligent assistant."} ] 

# messages = [
#     {"role": "system", "content": "You are an intelligent assistant."},
#     {"role": "user", "content": "Prompt 1: Your first prompt here."},
#     {"role": "assistant", "content": "Response 1: (GPT-3.5's response to prompt 1)"},
#     {"role": "user", "content": "Prompt 2: Your second prompt here."},
#     {"role": "assistant", "content": "Response 2: (GPT-3.5's response to prompt 2)"},
#     # Add more prompts and responses as needed
# ]



dataframe1 = pd.read_excel('output_fin_jama_big2.xlsx')
dataframe2=dataframe1

dataframe2['message']=""
dataframe2['Answer_chatgpt']=""
dataframe2['Explanation']=""
dataframe2['Actual_Correct_option']=""
dataframe2['IsChatGptCorrect']=""
dataframe2['ModifiedMedicalField']=""


for ind in dataframe1.index:
    if ind==1:
        break
    
    title=dataframe1['Title'][ind]
    caseart=dataframe1['Case'][ind]
    question=dataframe1['MCQ_question'][ind]
    option1=dataframe1['Option1'][ind]
    option2=dataframe1['Option2'][ind]
    option3=dataframe1['Option3'][ind]
    option4=dataframe1['Option4'][ind]
    correct_option=dataframe1['Correct_option'][ind]
    

#     message="Title: "+title+" Case is: "+caseart+question+" "+"A: "+option1+" ,"+" "+"B: "+option2+" ,"+" "+"C: "+option3+" ,"+" "+"D: "+option4+". "+"Please choose an answer option. The output format is:  (fill in the letter of the answer). Alphabetical letter only"
#     #print(message)
#     if len(message)>=4050:
#         print("Word exceed", ind)
#         continue
#     messages.append( 
#             {"role": "user", "content": message}, 
#         )
#     messages = [ {"role": "system", "content":  
#               "You are a intelligent assistant."} ] 
#     messages.append( 
#             {"role": "user", "content": message}, 
#         )
    
#     # chat = openai.ChatCompletion.create( model="gpt-3.5-turbo", messages=messages )
#     # reply = chat.choices[0].message.content
#     dataframe2.at[ind,'message']=message
#     chat = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages)
#     reply = chat.choices[0].message.content
#     print(reply)






# # Create the messages list
# messages = [
#     {"role": "system", "content": "You are an intelligent assistant."},
#     {"role": "user", "content": "Prompt 1: Please provide an explanation for the following question with MCQs.\n\nWhat is the capital of France?\nA) London\nB) Berlin\nC) Paris\nD) Madrid"},
#     {"role": "assistant", "content": "Response 1: The capital of France is Paris."},
#     {"role": "user", "content": "Prompt 2: Now, based on the explanation provided in the previous response, please answer the MCQ.\n\nWhat is the capital of France?"},
#     {"role": "assistant", "content": "Response 2: The capital of France is Paris."},
# ]

# # Send the messages to GPT-3.5
# chat = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages)

# # Extract the answer generated by the model
# answer = chat.choices[0].message.content

# # You can use 'answer' for further processing or display it as needed
# print(answer)

    

    # Create the first prompt
    first_prompt="Title: "+title+"\n"+ "Case is: "+caseart
    #first_prompt = "Title: Coin-Shaped Opacities in the Stomach\nCase is: A 50-year-old man with end-stage kidney disease receiving hemodialysis was admitted to the hospital for treatment of calciphylaxis and foot cellulitis... What Would You Do Next? A: Administer activated charcoal, B: Arrange endoscopy, C: Perform gastric lavage, D: Provide supportive care."
    print(first_prompt)
    # Send the first prompt to GPT-3.5-turbo to get a response
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are an intelligent assistant."},
            {"role": "user", "content": first_prompt}
        ]
    )

    # Extract information from the first response
    first_response_text = response.choices[0].message.content
    #print(first_response_text)
    print("yasshshshshshsh")
    # Include the information in the second prompt
    second_prompt = f"Prompt 2: Based on the provided information in the first response:\n{first_response_text}\n"+question+" "+"A: "+option1+" ,"+" "+"B: "+option2+" ,"+" "+"C: "+option3+" ,"+" "+"D: "+option4+". "+"Please choose an answer option. The output format is:  (fill in the letter of the answer). Alphabetical letter only"
    print(second_prompt)
    # Send the second prompt to GPT-3.5-turbo
    second_response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are an intelligent assistant."},
            {"role": "user", "content": second_prompt}
        ]
    )

    # Extract the answer generated by the model in response to the second prompt
    correct_option = second_response.choices[0].message.content.strip()
    answer_pattern = re.compile(r'\b([A-D]):', re.DOTALL)
            #answer_pattern = r'\b([A-D]):'
            #explanation_pattern = re.compile(r'Explanation:(.*?)$', re.DOTALL)
    answer_match = answer_pattern.search(correct_option)

    # You can use 'correct_option' for further processing or display it as needed
    print("Correct Option:", answer_match.group(1))